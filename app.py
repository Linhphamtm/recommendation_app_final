# Final App - Product & User Recommendation System
# Ng∆∞·ªùi th·ª±c hi·ªán: Ph·∫°m Th·ªã Mai Linh
# Ng√†y b√°o c√°o: 13/04/2025

import streamlit as st
import pickle
import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
from wordcloud import WordCloud
import matplotlib.pyplot as plt

# ================================
# C·∫•u h√¨nh App
# ================================
st.set_page_config(page_title='H·ªá th·ªëng g·ª£i √Ω s·∫£n ph·∫©m', layout='wide', initial_sidebar_state='expanded')

# ================================
# Sidebar - Navigation v√† Th√¥ng tin
# ================================
st.sidebar.title('üìÇ ƒêi·ªÅu h∆∞·ªõng')
page = st.sidebar.radio("Ch·ªçn m·ª•c", ['Insight', 'App'])

st.sidebar.markdown("""
### üßë‚Äçüíª Ng∆∞·ªùi th·ª±c hi·ªán
**Ph·∫°m Th·ªã Mai Linh**

### üìÖ Ng√†y b√°o c√°o
**13/04/2025**
""")

# ================================
# Load model v√† d·ªØ li·ªáu ƒë·ªìng b·ªô
# ================================
with open('product_cosine.pkl', 'rb') as f:
    product_model = pickle.load(f)

vectorizer = product_model['vectorizer']
tfidf_matrix = product_model['tfidf_matrix']
df_product = product_model['dataframe']

with open('surprise_model.pkl', 'rb') as f:
    user_model = pickle.load(f)

algo = user_model['model']
df_user = user_model['df_sample']

# Ch·ªâ l·∫•y user_id c√≥ product_id tr√πng v·ªõi df_product
valid_user_ids = df_user[df_user['product_id'].isin(df_product['product_id'])]['user_id'].unique().tolist()

# ================================
# Trang Insight
# ================================
if page == 'Insight':
    st.title('üìä Project Insight')

    # --- M·ª•c ti√™u Project ---
    st.header('üéØ M·ª•c ti√™u project')
    st.markdown("""
    X√¢y d·ª±ng h·ªá th·ªëng g·ª£i √Ω s·∫£n ph·∫©m th·ªùi trang nam tr√™n Shopee, nh·∫±m h·ªó tr·ª£ ng∆∞·ªùi ti√™u d√πng d·ªÖ d√†ng t√¨m ki·∫øm s·∫£n ph·∫©m ph√π h·ª£p d·ª±a tr√™n:

    - **G·ª£i √Ω theo n·ªôi dung s·∫£n ph·∫©m:** D·ª±a tr√™n m√¥ t·∫£ chi ti·∫øt c·ªßa s·∫£n ph·∫©m.
    - **G·ª£i √Ω theo ng∆∞·ªùi d√πng:** D·ª±a tr√™n l·ªãch s·ª≠ ƒë√°nh gi√° v√† t∆∞∆°ng t√°c c·ªßa ng∆∞·ªùi d√πng.
    """)

    # --- EDA ---
    st.header('üìä Kh√°m ph√° d·ªØ li·ªáu (EDA)')

    # Wordcloud m√¥ t·∫£ s·∫£n ph·∫©m
    st.subheader('Wordcloud m√¥ t·∫£ s·∫£n ph·∫©m')
    text = ' '.join(df_product['final_cleaned_tokens'].apply(lambda x: ' '.join(x)))
    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)
    fig, ax = plt.subplots(figsize=(10, 5))
    ax.imshow(wordcloud, interpolation='bilinear')
    ax.axis('off')
    st.pyplot(fig)

    # Ph√¢n ph·ªëi rating s·∫£n ph·∫©m
    st.subheader('Ph√¢n ph·ªëi rating s·∫£n ph·∫©m')
    st.bar_chart(df_product['rating'].value_counts().sort_index())

    # Ph√¢n ph·ªëi rating user-based
    st.subheader('Ph√¢n ph·ªëi rating t·ª´ ng∆∞·ªùi d√πng')
    st.bar_chart(df_user['rating'].value_counts().sort_index())

    # --- C√°c b∆∞·ªõc l√†m s·∫°ch d·ªØ li·ªáu ---
    st.header('üßπ C√°c b∆∞·ªõc l√†m s·∫°ch d·ªØ li·ªáu')
    st.markdown("""
    **B∆∞·ªõc 1:** Chu·∫©n h√≥a vƒÉn b·∫£n m√¥ t·∫£ s·∫£n ph·∫©m.
    - X·ª≠ l√Ω encoding, chu·∫©n h√≥a Unicode, lo·∫°i b·ªè k√Ω t·ª± kh√¥ng c·∫ßn thi·∫øt.

    **B∆∞·ªõc 2:** Lo·∫°i b·ªè nhi·ªÖu v√† pattern kh√¥ng mong mu·ªën.
    - X√≥a c√°c m·∫´u spam, t·ª´ ng·ªØ qu·∫£ng c√°o tr√πng l·∫∑p.

    **B∆∞·ªõc 3:** T√°ch t·ª´ (Tokenization) v√† lo·∫°i b·ªè stopword.
    - T√°ch c√°c t·ª´ trong c√¢u v√† lo·∫°i b·ªè t·ª´ d·ª´ng kh√¥ng c·∫ßn thi·∫øt.

    **B∆∞·ªõc 4:** K·∫øt qu·∫£ cu·ªëi c√πng.
    - VƒÉn b·∫£n s·∫°ch v√† ƒë∆∞·ª£c x·ª≠ l√Ω trong c·ªôt `final_cleaned_tokens` s·∫µn s√†ng cho vector h√≥a.
    """)

    # --- Thu·∫≠t to√°n s·ª≠ d·ª•ng ---
    st.header('üß© Thu·∫≠t to√°n s·ª≠ d·ª•ng')
    st.markdown("""
    - **Cosine Similarity:** ƒêo l∆∞·ªùng m·ª©c ƒë·ªô t∆∞∆°ng ƒë·ªìng gi·ªØa c√°c s·∫£n ph·∫©m d·ª±a tr√™n m√¥ t·∫£.
    - **Surprise SVD:** Ph√¢n r√£ ma tr·∫≠n ƒë·ªÉ d·ª± ƒëo√°n s·∫£n ph·∫©m ph√π h·ª£p v·ªõi t·ª´ng ng∆∞·ªùi d√πng.
    """)

    # --- ƒê√°nh gi√° thu·∫≠t to√°n ---
    st.header('üìà ƒê√°nh gi√° thu·∫≠t to√°n s·ª≠ d·ª•ng')
    st.markdown("""
    **Cosine Similarity:**
    - ∆Øu ƒëi·ªÉm: D·ªÖ tri·ªÉn khai, tr·ª±c quan, ho·∫°t ƒë·ªông t·ªët khi d·ªØ li·ªáu m√¥ t·∫£ s·∫£n ph·∫©m ƒë∆∞·ª£c l√†m s·∫°ch t·ªët.
    - H·∫°n ch·∫ø: Kh√¥ng c√° nh√¢n h√≥a theo ng∆∞·ªùi d√πng.

    **Surprise SVD:**
    - ∆Øu ƒëi·ªÉm: C√° nh√¢n h√≥a g·ª£i √Ω theo l·ªãch s·ª≠ ng∆∞·ªùi d√πng.
    - H·∫°n ch·∫ø: C·∫ßn ƒë·ªß d·ªØ li·ªáu ng∆∞·ªùi d√πng ƒë·ªÉ hu·∫•n luy·ªán ch√≠nh x√°c.
    """)

# ================================
# Trang App (Recommendation)
# ================================
elif page == 'App':
    st.title('ü§ñ Recommendation App')

    tab1, tab2 = st.tabs(["üõçÔ∏è G·ª£i √Ω theo s·∫£n ph·∫©m", "üë• G·ª£i √Ω theo ng∆∞·ªùi d√πng"])

    # --- Tab 1: Product-based ---
    with tab1:
        st.header('G·ª£i √Ω theo s·∫£n ph·∫©m (Content-based)')
        user_input = st.text_input('Nh·∫≠p m√¥ t·∫£ s·∫£n ph·∫©m b·∫°n mu·ªën t√¨m g·ª£i √Ω:')
        top_k = st.slider('S·ªë l∆∞·ª£ng s·∫£n ph·∫©m g·ª£i √Ω:', min_value=1, max_value=20, value=5)

        if st.button('üìä Hi·ªÉn th·ªã g·ª£i √Ω s·∫£n ph·∫©m'):
            if not user_input.strip():
                st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p m√¥ t·∫£ s·∫£n ph·∫©m ƒë·ªÉ nh·∫≠n g·ª£i √Ω.")
            else:
                user_input_vector = vectorizer.transform([user_input])
                sim_scores = list(enumerate(cosine_similarity(user_input_vector, tfidf_matrix)[0]))
                sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[:top_k]

                recommendations = []
                for idx, score in sim_scores:
                    row = df_product.iloc[idx]
                    recommendations.append({
                        '·∫¢nh': row['image'] if pd.notna(row['image']) else '',
                        'T√™n s·∫£n ph·∫©m': row['product_name'],
                        'Gi√°': f"{row['price']:.0f} VND" if pd.notna(row['price']) else 'N/A',
                        'ƒêi·ªÉm t∆∞∆°ng ƒë·ªìng': f"{score:.2f}",
                        'Link': f"[Xem s·∫£n ph·∫©m]({row['link']})" if pd.notna(row['link']) else "N/A"
                    })

                st.markdown("### üéØ K·∫øt qu·∫£ g·ª£i √Ω:")

                for rec in recommendations:
                    cols = st.columns([1, 3])
                    if rec['·∫¢nh']:
                        cols[0].image(rec['·∫¢nh'], width=120)
                    else:
                        cols[0].empty()

                    cols[1].markdown(f"**{rec['T√™n s·∫£n ph·∫©m']}**")
                    cols[1].markdown(f"üí∞ {rec['Gi√°']} | ‚≠êÔ∏è ƒêi·ªÉm t∆∞∆°ng ƒë·ªìng: {rec['ƒêi·ªÉm t∆∞∆°ng ƒë·ªìng']}")
                    cols[1].markdown(f"üîó {rec['Link']}")
                    cols[1].markdown("---")

                results_df = pd.DataFrame(recommendations)
                csv = results_df.to_csv(index=False).encode('utf-8')
                st.download_button("üì• T·∫£i k·∫øt qu·∫£ v·ªÅ CSV", data=csv, file_name='recommendations_product.csv', mime='text/csv')

    # --- Tab 2: User-based ---
    with tab2:
        st.header('G·ª£i √Ω theo ng∆∞·ªùi d√πng (Collaborative filtering)')

        selected_user = st.selectbox('Ch·ªçn User b·∫°n mu·ªën t√¨m g·ª£i √Ω:', valid_user_ids)
        top_k_user = st.slider('S·ªë l∆∞·ª£ng s·∫£n ph·∫©m g·ª£i √Ω:', min_value=1, max_value=20, value=5, key='user_slider')

        if st.button('üìä Hi·ªÉn th·ªã g·ª£i √Ω ng∆∞·ªùi d√πng'):
            user_ratings = df_user[df_user['user_id'] == selected_user]
            if user_ratings.empty:
                st.warning("‚ö†Ô∏è Ng∆∞·ªùi d√πng n√†y kh√¥ng c√≥ ƒë√°nh gi√° trong d·ªØ li·ªáu!")
            else:
                all_product_ids = df_product['product_id'].unique()
                predictions = [(product_id, algo.predict(selected_user, product_id).est) for product_id in all_product_ids]
                predictions = sorted(predictions, key=lambda x: x[1], reverse=True)[:top_k_user]

                recommendations = []
                for pid, est in predictions:
                    row = df_product[df_product['product_id'] == pid].iloc[0]
                    recommendations.append({
                        '·∫¢nh': row['image'] if pd.notna(row['image']) else '',
                        'T√™n s·∫£n ph·∫©m': row['product_name'],
                        'Gi√°': f"{row['price']:.0f} VND" if pd.notna(row['price']) else 'N/A',
                        'Rating d·ª± ƒëo√°n': f"{est:.2f}",
                        'Link': f"[Xem s·∫£n ph·∫©m]({row['link']})" if pd.notna(row['link']) else "N/A"
                    })

                st.markdown("### üéØ K·∫øt qu·∫£ g·ª£i √Ω:")

                for rec in recommendations:
                    cols = st.columns([1, 3])
                    if rec['·∫¢nh']:
                        cols[0].image(rec['·∫¢nh'], width=120)
                    else:
                        cols[0].empty()

                    cols[1].markdown(f"**{rec['T√™n s·∫£n ph·∫©m']}**")
                    cols[1].markdown(f"üí∞ {rec['Gi√°']} | ‚≠êÔ∏è Rating d·ª± ƒëo√°n: {rec['Rating d·ª± ƒëo√°n']}")
                    cols[1].markdown(f"üîó {rec['Link']}")
                    cols[1].markdown("---")

                results_df_user = pd.DataFrame(recommendations)
                csv = results_df_user.to_csv(index=False).encode('utf-8')
                st.download_button("üì• T·∫£i k·∫øt qu·∫£ v·ªÅ CSV", data=csv, file_name='recommendations_user.csv', mime='text/csv')
